{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have a catalog of repeating earthquakes, and I want to download seismic waveforms corresponding to these repeating earthquakes. However, when I look at the list of stations available in the seismic network, there are more than 6000. I do not want to download data from 6000 stations, so I want to filter only the seismic stations that are relevant for what I want to do with my waveforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Address of the website to download data\n",
    "url = 'http://ncedc.org/ftp/pub/doc/NC.info/NC.channel.summary.day'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful Python modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import pickle\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from math import cos, sin, pi, sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data from the website into a Python dataframe\n",
    "s = requests.get(url).content\n",
    "data = pd.read_csv(io.StringIO(s.decode('utf-8')), header=None, skiprows=2, sep='\\s+', usecols=list(range(0, 13)))\n",
    "data.columns = ['station', 'network', 'channel', 'location', 'rate', 'start_time', 'end_time', 'latitude', 'longitude', 'elevation', 'depth', 'dip', 'azimuth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform columns start_time and end_time into datetime format\n",
    "startdate = pd.to_datetime(data['start_time'], format='%Y/%m/%d,%H:%M:%S')\n",
    "data['start_time'] = startdate\n",
    "# Avoid 'OutOfBoundsDatetime' error with year 3000\n",
    "enddate = data['end_time'].str.replace('3000', '2025')\n",
    "enddate = pd.to_datetime(enddate, format='%Y/%m/%d,%H:%M:%S')\n",
    "data['end_time'] = enddate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After discussing with my adviser, we decided than only the following channels are relevant for the work we want to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = ['BHE', 'BHN', 'BHZ', 'BH1', 'BH2', \\\n",
    "            'EHE', 'EHN', 'EHZ', 'EH1', 'EH2', \\\n",
    "            'HHE', 'HHN', 'HHZ', 'HH1', 'HH2', \\\n",
    "            'SHE', 'SHN', 'SHZ', 'SH1', 'SH2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First question\n",
    "\n",
    "Filter the dataset to keep only the rows with the channels as defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fl = data.loc[data.channel.isin(channels)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My earthquake catalog starts on 2007/07/01 and ends on 2009/07/01. I am only interested in stations that started recording before 2007/07/01 and ended recording after 2009/07/01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second question\n",
    "\n",
    "Filter the dataset to keep only stations that started recording before 2007/07/01 and ended recording after 2009/07/01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_fl = data_fl[(data_fl.start_time < '2007-07-01') & (data_fl.end_time > '2009-07-01')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I only want to keep the stations that are located less than 100 km from my repeating earthquakes. For stations farther away, the signal-to-noise ratio would be too low.\n",
    "\n",
    "The earthquakes are located at latitude = 40.09 and longitude = -122.87. Here is a function to compute the distance from the station to the earthquakes, and to add a column distance to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 6378.136\n",
    "e = 0.006694470\n",
    "lat0 = 40.09000\n",
    "lon0 = -122.87000\n",
    "dx = (pi / 180.0) * a * cos(lat0 * pi / 180.0) / sqrt(1.0 - e * e * sin(lat0 * pi / 180.0) * sin(lat0 * pi / 180.0))\n",
    "dy = (3.6 * pi / 648.0) * a * (1.0 - e * e) / ((1.0 - e * e * sin(lat0 * pi / 180.0) * sin(lat0 * pi / 180.0)) ** 1.5)\n",
    "x = dx * (data['longitude'] - lon0)\n",
    "y = dy * (data['latitude'] - lat0)\n",
    "data_fl['distance'] = np.sqrt(np.power(x, 2.0) + np.power(y, 2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third question\n",
    "\n",
    "Filter the dataset to keep only stations that are less than 100 km from the earthquakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fl = data_fl[data_fl.distance < 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I want to group the result such that the final result looks like:\n",
    "\n",
    "|station|network|location|latitude|longitude |elevation|depth|distance |channel    |start_time         |end_time           |\n",
    "|-------|-------|--------|--------|----------|---------|-----|---------|-----------|-------------------|-------------------|\n",
    "|KBS \t|NC \t|-- \t |39.91719|-123.59561|1120.0   |0.0  |64.720762|SHZ        |2002-10-17 00:00:00|2011-10-27 21:25:00|\n",
    "|KCPB \t|NC \t|-- \t |39.68631|-123.58242|1261.0   |0.0  |75.502041|HHZ,HHN,HHE|2006-10-18 00:08:00|2010-11-01 22:00:00|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want all different channels to be grouped together, instead of having one row per channel. I also want to get the start_time end end_time for each station, instead of having it for each channel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the following function to group the channels together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    \"\"\"\n",
    "    Concatenate channels\n",
    "    \"\"\"\n",
    "    result = '%s' % ','.join(x)\n",
    "    result = list(set(result.split(',')))\n",
    "    result = '%s' % ','.join(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth question\n",
    "\n",
    "Use the pandas function agg to group the channels of a given station together, and compute the least recent start_time and the most recent end_time for each station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station</th>\n",
       "      <th>channel</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GBB</th>\n",
       "      <th>EHZ</th>\n",
       "      <td>2000-12-06 18:38:00</td>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GCK</th>\n",
       "      <th>EHZ</th>\n",
       "      <td>2000-06-06 21:58:00</td>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFC</th>\n",
       "      <th>EHZ</th>\n",
       "      <td>2001-04-03 23:25:00</td>\n",
       "      <td>2020-03-18 22:53:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHM</th>\n",
       "      <th>EHZ</th>\n",
       "      <td>1987-05-01 00:00:00</td>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRO</th>\n",
       "      <th>EHZ</th>\n",
       "      <td>1990-12-13 23:30:00</td>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTC</th>\n",
       "      <th>SHZ</th>\n",
       "      <td>2002-10-17 00:00:00</td>\n",
       "      <td>2011-10-27 21:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTS</th>\n",
       "      <th>EHZ</th>\n",
       "      <td>1987-05-01 00:00:00</td>\n",
       "      <td>2020-10-19 16:57:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KBN</th>\n",
       "      <th>SHZ</th>\n",
       "      <td>2002-10-17 00:00:00</td>\n",
       "      <td>2011-10-27 21:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KBS</th>\n",
       "      <th>SHZ</th>\n",
       "      <td>2002-10-17 00:00:00</td>\n",
       "      <td>2011-10-27 21:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KCR</th>\n",
       "      <th>SHZ</th>\n",
       "      <td>2002-08-29 00:00:00</td>\n",
       "      <td>2011-11-01 17:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KCS</th>\n",
       "      <th>SHZ</th>\n",
       "      <td>2002-08-28 00:00:00</td>\n",
       "      <td>2011-11-01 17:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KFP</th>\n",
       "      <th>SHZ</th>\n",
       "      <td>2002-10-17 00:00:00</td>\n",
       "      <td>2011-10-27 21:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KIP</th>\n",
       "      <th>SHZ</th>\n",
       "      <td>2002-10-17 00:00:00</td>\n",
       "      <td>2011-10-27 21:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KKP</th>\n",
       "      <th>SHZ</th>\n",
       "      <td>2002-08-29 00:00:00</td>\n",
       "      <td>2011-11-01 17:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KPP</th>\n",
       "      <th>SHZ</th>\n",
       "      <td>2002-08-29 00:00:00</td>\n",
       "      <td>2011-11-01 17:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KRK</th>\n",
       "      <th>SHZ</th>\n",
       "      <td>2002-10-17 00:00:00</td>\n",
       "      <td>2011-10-27 21:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBP</th>\n",
       "      <th>SHZ</th>\n",
       "      <td>2002-03-28 21:25:00</td>\n",
       "      <td>2011-12-08 23:21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDB</th>\n",
       "      <th>SHZ</th>\n",
       "      <td>2002-03-28 21:10:00</td>\n",
       "      <td>2011-12-08 23:21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGP</th>\n",
       "      <th>SHZ</th>\n",
       "      <td>2002-03-28 20:42:00</td>\n",
       "      <td>2011-12-08 23:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LPG</th>\n",
       "      <th>SHZ</th>\n",
       "      <td>2002-03-28 20:45:00</td>\n",
       "      <td>2011-12-08 23:21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LRB</th>\n",
       "      <th>SHZ</th>\n",
       "      <td>2002-03-28 21:25:00</td>\n",
       "      <td>2011-12-08 23:21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSF</th>\n",
       "      <th>SHZ</th>\n",
       "      <td>2002-03-28 21:25:00</td>\n",
       "      <td>2011-12-08 23:21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LTC</th>\n",
       "      <th>SHZ</th>\n",
       "      <td>2002-03-28 21:25:00</td>\n",
       "      <td>2011-12-08 23:21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LVR</th>\n",
       "      <th>SHZ</th>\n",
       "      <td>2002-03-28 21:10:00</td>\n",
       "      <td>2011-12-08 23:21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LWH</th>\n",
       "      <th>SHZ</th>\n",
       "      <td>2002-03-28 21:25:00</td>\n",
       "      <td>2011-12-08 23:21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCR</th>\n",
       "      <th>EHZ</th>\n",
       "      <td>1992-01-22 23:00:00</td>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         start_time            end_time\n",
       "station channel                                        \n",
       "GBB     EHZ     2000-12-06 18:38:00 2025-01-01 00:00:00\n",
       "GCK     EHZ     2000-06-06 21:58:00 2025-01-01 00:00:00\n",
       "GFC     EHZ     2001-04-03 23:25:00 2020-03-18 22:53:00\n",
       "GHM     EHZ     1987-05-01 00:00:00 2025-01-01 00:00:00\n",
       "GRO     EHZ     1990-12-13 23:30:00 2025-01-01 00:00:00\n",
       "GTC     SHZ     2002-10-17 00:00:00 2011-10-27 21:25:00\n",
       "GTS     EHZ     1987-05-01 00:00:00 2020-10-19 16:57:00\n",
       "KBN     SHZ     2002-10-17 00:00:00 2011-10-27 21:25:00\n",
       "KBS     SHZ     2002-10-17 00:00:00 2011-10-27 21:25:00\n",
       "KCR     SHZ     2002-08-29 00:00:00 2011-11-01 17:05:00\n",
       "KCS     SHZ     2002-08-28 00:00:00 2011-11-01 17:05:00\n",
       "KFP     SHZ     2002-10-17 00:00:00 2011-10-27 21:25:00\n",
       "KIP     SHZ     2002-10-17 00:00:00 2011-10-27 21:25:00\n",
       "KKP     SHZ     2002-08-29 00:00:00 2011-11-01 17:05:00\n",
       "KPP     SHZ     2002-08-29 00:00:00 2011-11-01 17:05:00\n",
       "KRK     SHZ     2002-10-17 00:00:00 2011-10-27 21:25:00\n",
       "LBP     SHZ     2002-03-28 21:25:00 2011-12-08 23:21:00\n",
       "LDB     SHZ     2002-03-28 21:10:00 2011-12-08 23:21:00\n",
       "LGP     SHZ     2002-03-28 20:42:00 2011-12-08 23:59:00\n",
       "LPG     SHZ     2002-03-28 20:45:00 2011-12-08 23:21:00\n",
       "LRB     SHZ     2002-03-28 21:25:00 2011-12-08 23:21:00\n",
       "LSF     SHZ     2002-03-28 21:25:00 2011-12-08 23:21:00\n",
       "LTC     SHZ     2002-03-28 21:25:00 2011-12-08 23:21:00\n",
       "LVR     SHZ     2002-03-28 21:10:00 2011-12-08 23:21:00\n",
       "LWH     SHZ     2002-03-28 21:25:00 2011-12-08 23:21:00\n",
       "OCR     EHZ     1992-01-22 23:00:00 2025-01-01 00:00:00"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fl.groupby(['station','channel']).agg({'start_time':lambda x: min(x), 'end_time':lambda x: max(x)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fifth question\n",
    "\n",
    "How many stations are left in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_fl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 26 stations left"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
